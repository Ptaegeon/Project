{"cells":[{"cell_type":"markdown","id":"a2bcba5f-002e-4f49-9622-ada6117faf0a","metadata":{"id":"a2bcba5f-002e-4f49-9622-ada6117faf0a"},"source":["## Import"]},{"cell_type":"code","execution_count":null,"id":"2b0d9b68-7102-4eca-9543-3b9b8acafc6e","metadata":{"id":"2b0d9b68-7102-4eca-9543-3b9b8acafc6e"},"outputs":[],"source":["import random\n","import pandas as pd\n","import numpy as np\n","import os\n","import cv2\n","import zipfile\n","import math\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","\n","from tqdm.auto import tqdm\n","\n","import albumentations as A\n","from albumentations.pytorch.transforms import ToTensorV2\n","\n","import torchvision.models as models\n","from torchvision import transforms\n","\n","import warnings\n","warnings.filterwarnings(action='ignore')"]},{"cell_type":"code","execution_count":null,"id":"d13862e3-bb27-47af-9b58-a9fbf804df71","metadata":{"id":"d13862e3-bb27-47af-9b58-a9fbf804df71"},"outputs":[],"source":["device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"]},{"cell_type":"markdown","id":"fc7df3f2-62d0-4499-a46e-47d01699def0","metadata":{"id":"fc7df3f2-62d0-4499-a46e-47d01699def0"},"source":["## Hyperparameter Setting"]},{"cell_type":"code","execution_count":null,"id":"c3367399-9798-4e38-967b-fd2320b9a2b2","metadata":{"id":"c3367399-9798-4e38-967b-fd2320b9a2b2"},"outputs":[],"source":["CFG = {\n","    'IMG_SIZE':2048,\n","    'EPOCHS':30,\n","    'LEARNING_RATE':1e-4,\n","    'BATCH_SIZE':12,\n","    'SEED':41\n","}"]},{"cell_type":"markdown","id":"4254e860-ff82-43ba-bfa3-fcee4eb3ddbd","metadata":{"id":"4254e860-ff82-43ba-bfa3-fcee4eb3ddbd"},"source":["## Fixed RandomSeed"]},{"cell_type":"code","execution_count":null,"id":"101a714b-71b6-4475-a4ce-fa5f98bc2731","metadata":{"id":"101a714b-71b6-4475-a4ce-fa5f98bc2731"},"outputs":[],"source":["def seed_everything(seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = True\n","\n","seed_everything(CFG['SEED']) # Seed 고정"]},{"cell_type":"markdown","id":"05a4172e-5791-446f-9616-35c09d8bf25a","metadata":{"id":"05a4172e-5791-446f-9616-35c09d8bf25a"},"source":["## Data Load"]},{"cell_type":"code","execution_count":null,"id":"a62c78cd-4f40-4e98-b8a6-1b6f1d906b4d","metadata":{"id":"a62c78cd-4f40-4e98-b8a6-1b6f1d906b4d"},"outputs":[],"source":["train_df = pd.read_csv('./train.csv')\n","test_df = pd.read_csv('./test.csv')"]},{"cell_type":"markdown","id":"ac27ed36-8031-47a7-bd0d-a913513f2e8e","metadata":{"id":"ac27ed36-8031-47a7-bd0d-a913513f2e8e"},"source":["## CustomDataset"]},{"cell_type":"code","execution_count":null,"id":"be574dae-1f9a-4126-aeb9-b27e1c2dacd1","metadata":{"id":"be574dae-1f9a-4126-aeb9-b27e1c2dacd1"},"outputs":[],"source":["class CustomDataset(Dataset):\n","    def __init__(self, df, transforms, train_mode):\n","        self.df = df\n","        self.transforms = transforms\n","        self.train_mode = train_mode\n","\n","    def __getitem__(self, index):\n","        lr_path = self.df['LR'].iloc[index]\n","        lr_img = cv2.imread(lr_path)\n","        lr_img = cv2.resize(lr_img, (CFG['IMG_SIZE'], CFG['IMG_SIZE']), interpolation=cv2.INTER_CUBIC)\n","        if self.train_mode:\n","            hr_path = self.df['HR'].iloc[index]\n","            hr_img = cv2.imread(hr_path)\n","            if transforms is not None:\n","                transformed = self.transforms(image=lr_img, label=hr_img)\n","                lr_img = transformed['image'] / 255.\n","                hr_img = transformed['label'] / 255.\n","            return lr_img, hr_img\n","        else:\n","            file_name = lr_path.split('/')[-1]\n","            if transforms is not None:\n","                transformed = self.transforms(image=lr_img)\n","                lr_img = transformed['image'] / 255.\n","            return lr_img, file_name\n","        \n","    def __len__(self):\n","        return len(self.df)"]},{"cell_type":"code","execution_count":null,"id":"16c02d26-874c-4468-b1fd-2820fa0af731","metadata":{"id":"16c02d26-874c-4468-b1fd-2820fa0af731"},"outputs":[],"source":["def get_train_transform():\n","    return A.Compose([\n","        ToTensorV2(p=1.0)],\n","        additional_targets={'image': 'image', 'label': 'image'}\n","    )\n","\n","def get_test_transform():\n","    return A.Compose([\n","        ToTensorV2(p=1.0)],\n","        additional_targets={'image': 'image', 'label': 'image'}\n","    )"]},{"cell_type":"code","execution_count":null,"id":"9d880481-1965-499d-9caa-fdfa8526f789","metadata":{"id":"9d880481-1965-499d-9caa-fdfa8526f789"},"outputs":[],"source":["train_dataset = CustomDataset(train_df, get_train_transform(), True)\n","train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True, num_workers=6)\n","\n","test_dataset = CustomDataset(test_df, get_test_transform(), False)\n","test_loader = DataLoader(test_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=6)"]},{"cell_type":"markdown","id":"39962463-032f-490a-a76d-c03991795f38","metadata":{"id":"39962463-032f-490a-a76d-c03991795f38"},"source":["## Model Define"]},{"cell_type":"code","execution_count":null,"id":"2ce03b60-1410-40a5-90ba-504242d65e0d","metadata":{"id":"2ce03b60-1410-40a5-90ba-504242d65e0d"},"outputs":[],"source":["class SRCNN(nn.Module):\n","    def __init__(self, num_channels=3, feature_dim=64, map_dim=32):\n","        super(SRCNN, self).__init__()\n","        # Feature extraction layer.\n","        self.features = nn.Sequential(\n","            nn.Conv2d(num_channels, feature_dim, (9, 9), (1, 1), (4, 4)),\n","            nn.ReLU(True)\n","        )\n","        # Non-linear mapping layer.\n","        self.map = nn.Sequential(\n","            nn.Conv2d(feature_dim, map_dim, (5, 5), (1, 1), (2, 2)),\n","            nn.ReLU(True)\n","        )\n","        # Rebuild the layer.\n","        self.reconstruction = nn.Conv2d(map_dim, num_channels, (5, 5), (1, 1), (2, 2))\n","        # Initialize model weights.\n","        self._initialize_weights()\n","\n","    def forward(self, x):\n","        out = self.features(x)\n","        out = self.map(out)\n","        out = self.reconstruction(out)\n","        return out\n","\n","    # The filter weight of each layer is a Gaussian distribution with zero mean and\n","    # standard deviation initialized by random extraction 0.001 (deviation is 0)\n","    def _initialize_weights(self) -> None:\n","        for module in self.modules():\n","            if isinstance(module, nn.Conv2d):\n","                nn.init.normal_(module.weight.data, 0.0, math.sqrt(2 / (module.out_channels * module.weight.data[0][0].numel())))\n","                nn.init.zeros_(module.bias.data)\n","        nn.init.normal_(self.reconstruction.weight.data, 0.0, 0.001)\n","        nn.init.zeros_(self.reconstruction.bias.data)"]},{"cell_type":"markdown","id":"122af0aa-a1fd-4595-9488-35761e3cb596","metadata":{"id":"122af0aa-a1fd-4595-9488-35761e3cb596"},"source":["## Train"]},{"cell_type":"code","execution_count":null,"id":"a17df6b3-16c9-44dd-b0fd-ffb501fee749","metadata":{"id":"a17df6b3-16c9-44dd-b0fd-ffb501fee749"},"outputs":[],"source":["def train(model, optimizer, train_loader, scheduler, device):\n","    model.to(device)\n","    criterion = nn.MSELoss().to(device)\n","    best_model = None\n","    best_loss = 9999\n","    for epoch in range(1, CFG['EPOCHS']+1):\n","        model.train()\n","        train_loss = []\n","        for lr_img, hr_img in tqdm(iter(train_loader)):\n","            lr_img, hr_img = lr_img.float().to(device), hr_img.float().to(device)\n","            \n","            optimizer.zero_grad()\n","            \n","            pred_hr_img = model(lr_img)\n","            loss = criterion(pred_hr_img, hr_img)\n","            \n","            loss.backward()\n","            optimizer.step()\n","            \n","            train_loss.append(loss.item())\n","                    \n","        if scheduler is not None:\n","            scheduler.step()\n","        \n","        _train_loss = np.mean(train_loss)\n","        print(f'Epoch : [{epoch}] Train Loss : [{_train_loss:.5f}]')\n","         \n","        if best_loss > _train_loss:\n","            best_loss = _train_loss\n","            best_model = model\n","            \n","    return best_model"]},{"cell_type":"markdown","id":"51da39f9-904f-4abd-a7d2-cdf29c4a6c24","metadata":{"id":"51da39f9-904f-4abd-a7d2-cdf29c4a6c24"},"source":["## Run!!"]},{"cell_type":"code","execution_count":null,"id":"86142d9a-68b7-4d04-8423-49d28025411d","metadata":{"tags":[],"id":"86142d9a-68b7-4d04-8423-49d28025411d"},"outputs":[],"source":["model = nn.DataParallel(SRCNN())\n","model.eval()\n","\n","optimizer = torch.optim.Adam(params = model.parameters(), lr = CFG[\"LEARNING_RATE\"])\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n","\n","infer_model = train(model, optimizer, train_loader, scheduler, device)"]},{"cell_type":"markdown","id":"f7f10bb9-b7c8-4800-a1be-3bac2f29849e","metadata":{"id":"f7f10bb9-b7c8-4800-a1be-3bac2f29849e"},"source":["## Inference"]},{"cell_type":"code","execution_count":null,"id":"ab7ed1cf-53c8-4618-a113-0c858b14389c","metadata":{"id":"ab7ed1cf-53c8-4618-a113-0c858b14389c"},"outputs":[],"source":["def inference(model, test_loader, device):\n","    infer_model.to(device)\n","    model.eval()\n","    pred_img_list = []\n","    name_list = []\n","    with torch.no_grad():\n","        for lr_img, file_name in tqdm(iter(test_loader)):\n","            lr_img = lr_img.float().to(device)\n","            \n","            pred_hr_img = model(lr_img)\n","            \n","            for pred, name in zip(pred_hr_img, file_name):\n","                pred = pred.cpu().clone().detach().numpy()\n","                pred = pred.transpose(1, 2, 0)\n","                pred = pred*255.\n","                \n","                pred_img_list.append(pred.astype('uint8'))\n","                name_list.append(name)\n","    return pred_img_list, name_list"]},{"cell_type":"code","execution_count":null,"id":"f2e9cd59-48d3-46cf-b977-fbff148e55b7","metadata":{"colab":{"referenced_widgets":["3d6049e2644c49d3a1d3c7b354a1389d"]},"id":"f2e9cd59-48d3-46cf-b977-fbff148e55b7","outputId":"8f9b7ab8-e428-43fe-e33e-21ad03226fff"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3d6049e2644c49d3a1d3c7b354a1389d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["pred_img_list, pred_name_list = inference(infer_model, test_loader, device)"]},{"cell_type":"markdown","id":"07ae9501-6d6e-4536-b191-dba8b22d975a","metadata":{"id":"07ae9501-6d6e-4536-b191-dba8b22d975a"},"source":["## Submission"]},{"cell_type":"code","execution_count":null,"id":"7bd791c9-8ca0-4f99-941e-71190c7ce264","metadata":{"colab":{"referenced_widgets":["efcc5ff9da51476a91f482d36b08fd36"]},"id":"7bd791c9-8ca0-4f99-941e-71190c7ce264","outputId":"c9b12310-114f-4071-88d9-34501bd1dbdb"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"efcc5ff9da51476a91f482d36b08fd36","version_major":2,"version_minor":0},"text/plain":["0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Done.\n"]}],"source":["os.makedirs('./submission', exist_ok=True)\n","os.chdir(\"./submission/\")\n","sub_imgs = []\n","for path, pred_img in tqdm(zip(pred_name_list, pred_img_list)):\n","    cv2.imwrite(path, pred_img)\n","    sub_imgs.append(path)\n","submission = zipfile.ZipFile(\"../submission.zip\", 'w')\n","for path in sub_imgs:\n","    submission.write(path)\n","submission.close()\n","print('Done.')"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}