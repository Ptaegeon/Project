{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"english grammer.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOAOFlFNnyKr6TGJqU22uTR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard"},"cells":[{"cell_type":"code","source":["!pip install -U dill==0.3.3 pandas==1.1.5 numpy==1.19.5  scikit-learn==0.22.2 nltk==3.2.5 torch==1.7.1 torchtext==0.3.1\n","# !pip install -U torchtext==0.10.0\n","# !pip install -U torch==1.8.0 torchtext==0.9.0\n","# !pip install -U torch==1.7.1 torchtext==0.3.1\n","# !pip install torchtext==0.9.0 --quiet\n","# !pip install torchvision==0.9.0 --quiet"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"qtx4yy6e8oq-","executionInfo":{"status":"ok","timestamp":1659227078091,"user_tz":-540,"elapsed":144007,"user":{"displayName":"bong bong","userId":"17774416216702601338"}},"outputId":"ea5f3836-09ae-487f-f569-12d66e7a3422"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting dill==0.3.3\n","  Downloading dill-0.3.3-py2.py3-none-any.whl (81 kB)\n","\u001b[K     |████████████████████████████████| 81 kB 4.0 MB/s \n","\u001b[?25hCollecting pandas==1.1.5\n","  Downloading pandas-1.1.5-cp37-cp37m-manylinux1_x86_64.whl (9.5 MB)\n","\u001b[K     |████████████████████████████████| 9.5 MB 30.8 MB/s \n","\u001b[?25hCollecting numpy==1.19.5\n","  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n","\u001b[K     |████████████████████████████████| 14.8 MB 32.9 MB/s \n","\u001b[?25hCollecting scikit-learn==0.22.2\n","  Downloading scikit_learn-0.22.2-cp37-cp37m-manylinux1_x86_64.whl (7.1 MB)\n","\u001b[K     |████████████████████████████████| 7.1 MB 2.4 MB/s \n","\u001b[?25hCollecting nltk==3.2.5\n","  Downloading nltk-3.2.5.tar.gz (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 51.1 MB/s \n","\u001b[?25hCollecting torch==1.7.1\n","  Downloading torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (776.8 MB)\n","\u001b[K     |████████████████████████████████| 776.8 MB 17 kB/s \n","\u001b[?25hCollecting torchtext==0.3.1\n","  Downloading torchtext-0.3.1-py3-none-any.whl (62 kB)\n","\u001b[K     |████████████████████████████████| 62 kB 975 kB/s \n","\u001b[?25hRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas==1.1.5) (2022.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.1.5) (2.8.2)\n","Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.22.2) (1.7.3)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.22.2) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.2.5) (1.15.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1) (4.1.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.3.1) (2.23.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.3.1) (4.64.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.3.1) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.3.1) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.3.1) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.3.1) (2.10)\n","Building wheels for collected packages: nltk\n","  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for nltk: filename=nltk-3.2.5-py3-none-any.whl size=1392156 sha256=5857c5b4127fa5f13e953eff00a0e50a27dc1cd648d239882316e4d589fa3771\n","  Stored in directory: /root/.cache/pip/wheels/60/de/57/6bced01d340818a36413222e6efcc7766d1f1e4575782b6223\n","Successfully built nltk\n","Installing collected packages: numpy, torch, torchtext, scikit-learn, pandas, nltk, dill\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.21.6\n","    Uninstalling numpy-1.21.6:\n","      Successfully uninstalled numpy-1.21.6\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.12.0+cu113\n","    Uninstalling torch-1.12.0+cu113:\n","      Successfully uninstalled torch-1.12.0+cu113\n","  Attempting uninstall: torchtext\n","    Found existing installation: torchtext 0.13.0\n","    Uninstalling torchtext-0.13.0:\n","      Successfully uninstalled torchtext-0.13.0\n","  Attempting uninstall: scikit-learn\n","    Found existing installation: scikit-learn 1.0.2\n","    Uninstalling scikit-learn-1.0.2:\n","      Successfully uninstalled scikit-learn-1.0.2\n","  Attempting uninstall: pandas\n","    Found existing installation: pandas 1.3.5\n","    Uninstalling pandas-1.3.5:\n","      Successfully uninstalled pandas-1.3.5\n","  Attempting uninstall: nltk\n","    Found existing installation: nltk 3.7\n","    Uninstalling nltk-3.7:\n","      Successfully uninstalled nltk-3.7\n","  Attempting uninstall: dill\n","    Found existing installation: dill 0.3.5.1\n","    Uninstalling dill-0.3.5.1:\n","      Successfully uninstalled dill-0.3.5.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","yellowbrick 1.4 requires scikit-learn>=1.0.0, but you have scikit-learn 0.22.2 which is incompatible.\n","xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\n","torchvision 0.13.0+cu113 requires torch==1.12.0, but you have torch 1.7.1 which is incompatible.\n","torchaudio 0.12.0+cu113 requires torch==1.12.0, but you have torch 1.7.1 which is incompatible.\n","tensorflow 2.8.2+zzzcolab20220719082949 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n","multiprocess 0.70.13 requires dill>=0.3.5.1, but you have dill 0.3.3 which is incompatible.\n","imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.22.2 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n","cmdstanpy 1.0.4 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Successfully installed dill-0.3.3 nltk-3.2.5 numpy-1.19.5 pandas-1.1.5 scikit-learn-0.22.2 torch-1.7.1 torchtext-0.3.1\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]}}},"metadata":{}}]},{"cell_type":"code","source":["# dill.__version__"],"metadata":{"id":"ZybLV9qz633Z","executionInfo":{"status":"ok","timestamp":1659227078091,"user_tz":-540,"elapsed":12,"user":{"displayName":"bong bong","userId":"17774416216702601338"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","execution_count":63,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W0aIZ8Th0vDq","executionInfo":{"status":"ok","timestamp":1659231792779,"user_tz":-540,"elapsed":760,"user":{"displayName":"bong bong","userId":"17774416216702601338"}},"outputId":"2c6e56b1-6662-4ca5-b05c-8ab58fac8f93"},"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}],"source":["import dill\n","import time\n","import random\n","import numpy as np\n","from sklearn.metrics import roc_curve, auc\n","import nltk\n","nltk.download(\"punkt\")\n","from nltk.tokenize import word_tokenize\n","import pandas as pd\n","\n","import torch\n","import torch.nn as nn\n","from torchtext.data import Field, TabularDataset, BucketIterator, Iterator\n","import torch\n","# print(torch.__version__)\n","# print(torchtext.__version__)\n","# from torch.utils.tensorboard import SummaryWriter"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XPztO7dPxfUT","executionInfo":{"status":"ok","timestamp":1659227099492,"user_tz":-540,"elapsed":18326,"user":{"displayName":"bong bong","userId":"17774416216702601338"}},"outputId":"3f3442e3-72a8-4af9-d556-d9bae53f2cb2"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /gdrive\n"]}]},{"cell_type":"code","source":["%cd /gdrive/MyDrive/Deep-Project/\n","!cp data_processed.zip /content\n","%cd /content\n","!mkdir -p /content/processed/\n","!unzip -q data_processed.zip\n","# !curl -L -O https://github.com/bjpublic/DeepLearningProject/raw/main/08_%EC%88%98%EB%8A%A5_%EC%98%81%EC%96%B4_%ED%92%80%EA%B8%B0/data/raw/sat_problems.csv\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tbF3cyLVdulg","executionInfo":{"status":"ok","timestamp":1659230221389,"user_tz":-540,"elapsed":817,"user":{"displayName":"bong bong","userId":"17774416216702601338"}},"outputId":"71d4e148-96e8-486a-a121-b9359684b96e"},"execution_count":60,"outputs":[{"output_type":"stream","name":"stdout","text":["/gdrive/MyDrive/Deep-Project\n","/content\n"]}]},{"cell_type":"code","source":["DATA_PATH = '/content/data/processed/'\n","RANDOM_SEED = 2020\n","torch.manual_seed(RANDOM_SEED)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","np.random.seed(RANDOM_SEED)\n","random.seed(RANDOM_SEED)"],"metadata":{"id":"sQYw8QS873pw","executionInfo":{"status":"ok","timestamp":1659227100273,"user_tz":-540,"elapsed":5,"user":{"displayName":"bong bong","userId":"17774416216702601338"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["class LSTMClassifier(nn.Module):\n","    def __init__(self, num_embeddings, embedding_dim, hidden_size, num_layers, pad_idx):\n","        super().__init__()\n","        self.embed_layer = nn.Embedding(num_embeddings = num_embeddings, embedding_dim = embedding_dim,\n","                                        padding_idx = pad_idx)\n","        self.lstm_layer = nn.LSTM(input_size = embedding_dim, hidden_size= hidden_size,\n","                                  bidirectional= True, dropout=.5)\n","        self.last_layer = nn.Sequential(\n","            nn.Linear(hidden_size *2, hidden_size),\n","            nn.Dropout(.5),\n","            nn.LeakyReLU(),\n","            nn.Linear(hidden_size,1),\n","            nn.Sigmoid(),\n","        )\n","    def forward(self, x):\n","        embed_x = self.embed_layer(x)\n","        output, (_,_) = self.lstm_layer(embed_x)\n","        last_output = output[:, -1, :]              #LSTM output = (batch_size, embed_size, output_size), 가장 마지막 단어만 사용\n","        last_output = self.last_layer(last_output)\n","        return last_output"],"metadata":{"id":"zAh8c5ljNs-D","executionInfo":{"status":"ok","timestamp":1659227100274,"user_tz":-540,"elapsed":5,"user":{"displayName":"bong bong","userId":"17774416216702601338"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["class LSTMPoolingClassifier(nn.Module):\n","    def __init__(self, num_embeddings, embedding_dim, hidden_size, num_layers, pad_idx):\n","        super().__init__()\n","        self.embed_layer = nn.Embedding(num_embeddings = num_embeddings, embedding_dim = embedding_dim,\n","                                        padding_idx = pad_idx)\n","        self.lstm_layer = nn.LSTM(input_size = embedding_dim, hidden_size= hidden_size,\n","                                  bidirectional= True, dropout=.5, batch_first = True)\n","        self.last_layer = nn.Sequential(\n","            nn.Linear(hidden_size *2, 1),\n","            nn.Dropout(.5),\n","            nn.Sigmoid(),\n","        )\n","    def forward(self, x):\n","        embed_x = self.embed_layer(x)\n","        output, _ = self.lstm_layer(embed_x)\n","\n","        pool = nn.functional.max_pool1d(output.transpose(1,2), embed_x.shape[1])\n","        pool = pool.transpose(1,2).squeeze()\n","        output = self.last_layer(pool)\n","        return output.squeeze()\n","# class LSTMPoolingClassifier(nn.Module):\n","#     def __init__(self, num_embeddings, embedding_dim, hidden_size, num_layers, pad_idx):\n","#         super(LSTMPoolingClassifier, self).__init__()\n","#         self.embed_layer = nn.Embedding(num_embeddings=num_embeddings, embedding_dim=embedding_dim, padding_idx=pad_idx)\n","#         self.hidden_size = hidden_size\n","#         self.embedding_dim = embedding_dim\n","#         self.num_layers = num_layers\n","#         self.ih2h = nn.LSTM(embedding_dim, hidden_size, num_layers=num_layers,\n","#                             bidirectional=True, batch_first=True, dropout=0.5)\n","#         self.pool2o = nn.Linear(2 * hidden_size, 1)\n","#         self.sigmoid = nn.Sigmoid()\n","#         self.softmax = nn.Softmax()\n","#         self.dropout = nn.Dropout(p=0.5)\n","\n","#     def forward(self, x):\n","#         x = self.embed_layer(x)\n","#         o, _ = self.ih2h(x)\n","#         pool = nn.functional.max_pool1d(o.transpose(1, 2), x.shape[1])\n","#         pool = pool.transpose(1, 2).squeeze()\n","#         pool = self.dropout(pool)\n","#         output = self.sigmoid(self.pool2o(pool))\n","#         return output.squeeze()"],"metadata":{"id":"nZf9XAurqK-w","executionInfo":{"status":"ok","timestamp":1659229765833,"user_tz":-540,"elapsed":3,"user":{"displayName":"bong bong","userId":"17774416216702601338"}}},"execution_count":56,"outputs":[]},{"cell_type":"code","source":["TEXT = Field(\n","    sequential=True,\n","    use_vocab = True,\n","    tokenize= word_tokenize,\n","    lower = True,\n","    batch_first = True\n",")\n","\n","LABEL=Field(\n","    sequential = False,\n","    use_vocab = False,\n","    batch_first = True,\n",")\n","sat_train_data, sat_valid_data, sat_test_data = TabularDataset.splits(path='/content/data/processed/',train='sat_train.tsv',\n","                                                                      validation = 'sat_valid.tsv', test = 'sat_test.tsv',\n","                                                                      format = 'tsv', fields =[('text', TEXT), ('label',LABEL)],\n","                                                                      skip_header=1,)\n","sat_train_iterator, sat_valid_iterator, sat_test_iterator = BucketIterator.splits((sat_train_data, sat_valid_data, sat_test_data),\n","                                                                                  batch_size = 8,\n","                                                                                  device = None,\n","                                                                                  sort = False,)\n","TEXT.build_vocab(sat_train_data, min_freq =2)"],"metadata":{"id":"3fysk962XkkY","executionInfo":{"status":"ok","timestamp":1659227173314,"user_tz":-540,"elapsed":319,"user":{"displayName":"bong bong","userId":"17774416216702601338"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["cola_train_data, cola_valid_data, cola_test_data = TabularDataset.splits(path='/content/data/processed/',train='cola_train.tsv',\n","                                                                      validation = 'cola_valid.tsv', test = 'cola_test.tsv',\n","                                                                      format = 'tsv', fields =[('text', TEXT), ('label',LABEL)],\n","                                                                      skip_header=1,)\n","cola_train_iterator, cola_valid_iterator, cola_test_iterator = BucketIterator.splits((cola_train_data, cola_valid_data, cola_test_data),\n","                                                                                  batch_size = 32,\n","                                                                                  device = None,\n","                                                                                  sort = False,)\n","TEXT.build_vocab(cola_train_data, min_freq =2)"],"metadata":{"id":"W9PdF7TjDoI5","executionInfo":{"status":"ok","timestamp":1659227178636,"user_tz":-540,"elapsed":1369,"user":{"displayName":"bong bong","userId":"17774416216702601338"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# sat_train_iterator\n","# next(iter(cola_train_iterator)).text\n","# # print(batch.text)"],"metadata":{"id":"-Ih8ZoPnDqrj","executionInfo":{"status":"ok","timestamp":1659227178636,"user_tz":-540,"elapsed":3,"user":{"displayName":"bong bong","userId":"17774416216702601338"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["def train(model, train_loader, optimizer, criterion, device):\n","\n","    model.train()\n","    epoch_loss = 0\n","    for i, batch in enumerate(train_loader):\n","        optimizer.zero_grad()\n","        text = batch.text\n","        if text.shape[0] >1:\n","            label = batch.label.type(torch.FloatTensor)\n","            text = text.to(device)\n","            label = label.to(device)\n","            output = model(text).flatten()\n","            loss = criterion(output, label)\n","            loss.backward()\n","            optimizer.step()\n","            epoch_loss += loss.item()\n","\n","            writer.add_scalar('training loss',\n","                loss,\n","                epoch * len(train_loader) + i)\n","            \n","    return epoch_loss / len(train_loader)\n","\n","def evaluate(model, valid_loader, criterion, device):\n","    model.eval()\n","    epoch_loss = 0\n","    with torch.no_grad():\n","        for i, batch in enumerate(valid_loader):\n","            text = batch.text\n","            label = batch.label.type(torch.FloatTensor)\n","            text = text.to(device)\n","            label = label.to(device)\n","            output = model(text).flatten()\n","            loss = criterion(output, label)\n","            epoch_loss += loss.item()\n","\n","            writer.add_scalar('training loss',\n","                loss,\n","                epoch * len(valid_loader) + i)\n","\n","    return epoch_loss / len(valid_loader)"],"metadata":{"id":"PeamY7XjdkVC","executionInfo":{"status":"ok","timestamp":1659233589435,"user_tz":-540,"elapsed":321,"user":{"displayName":"bong bong","userId":"17774416216702601338"}}},"execution_count":78,"outputs":[]},{"cell_type":"code","source":["PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n","N_EPOCHS = 20\n","\n","lstm_classifier = LSTMClassifier(\n","    num_embeddings = len(TEXT.vocab),\n","    embedding_dim = 100,\n","    hidden_size = 200,\n","    num_layers = 4,\n","    pad_idx = PAD_IDX\n",")\n","\n","lstm_pool_classifier = LSTMPoolingClassifier(\n","    num_embeddings = len(TEXT.vocab),\n","    embedding_dim = 100,\n","    hidden_size = 400,\n","    num_layers = 4,\n","    pad_idx = PAD_IDX\n",")\n","\n","device = 'cpu'\n","if torch.cuda.is_available() :\n","    device = \"cuda\"\n","\n","_ = lstm_classifier.to(device)\n","optimizer = torch.optim.Adam(lstm_classifier.parameters())\n","bce_loss_fn = nn.BCELoss()\n","\n","_ = lstm_pool_classifier.to(device)\n","optimizer_pool = torch.optim.Adam(lstm_pool_classifier.parameters(), lr=0.01)\n","bce_loss_fn_pool = nn.BCELoss()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VHbEMfwHmAfL","executionInfo":{"status":"ok","timestamp":1659233596073,"user_tz":-540,"elapsed":347,"user":{"displayName":"bong bong","userId":"17774416216702601338"}},"outputId":"eafcac6c-b4c0-468d-8b73-3ff938f7c8b7"},"execution_count":79,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:61: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n","  \"num_layers={}\".format(dropout, num_layers))\n"]}]},{"cell_type":"code","source":["mode = 'sat_'\n","dataset = cola_train_iterator\n","valid_set = cola_valid_iterator\n","# train_model = lstm_classifier\n","\n","\n","if mode ==  'sat_':\n","    dataset = sat_train_iterator\n","    valid_set = sat_valid_iterator\n","elif mode == 'pool':\n","    train_model = lstm_pool_classifier\n","    optimizer = optimizer_pool\n","    bce_loss_fn = bce_loss_fn_pool\n","\n","for epoch in range(20):\n","    train_loss = train(train_model, dataset, optimizer, bce_loss_fn, device)\n","    valid_loss = evaluate(train_model, valid_set, bce_loss_fn, device)\n","    print(f'Epoch : {epoch +1 :02}    Train loss : {train_loss : .5f}   val loss : {valid_loss : .5f}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":538},"id":"xmzzdZwcnXMQ","executionInfo":{"status":"error","timestamp":1659233675261,"user_tz":-540,"elapsed":75984,"user":{"displayName":"bong bong","userId":"17774416216702601338"}},"outputId":"546e0040-ea64-4aa7-cdaa-7b1b1806fc8f"},"execution_count":80,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch : 01    Train loss :  0.40800   val loss :  0.34309\n","Epoch : 02    Train loss :  0.37597   val loss :  0.34309\n","Epoch : 03    Train loss :  0.37399   val loss :  0.34309\n","Epoch : 04    Train loss :  0.39258   val loss :  0.34309\n","Epoch : 05    Train loss :  0.42615   val loss :  0.34309\n","Epoch : 06    Train loss :  0.41156   val loss :  0.34309\n","Epoch : 07    Train loss :  0.39638   val loss :  0.34309\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-80-9fe648e9ab67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbce_loss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mvalid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbce_loss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch : {epoch +1 :02}    Train loss : {train_loss : .5f}   val loss : {valid_loss : .5f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-78-e9a5f357aad9>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, optimizer, criterion, device)\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["from copy import deepcopy \n","before_tuning_lstm_classifier = deepcopy(lstm_classifier)\n","before_tuning_lstm_classifier_pool = deepcopy(lstm_pool_classifier)\n"],"metadata":{"id":"yLDqKrBv_TDm","executionInfo":{"status":"ok","timestamp":1659228665696,"user_tz":-540,"elapsed":6,"user":{"displayName":"bong bong","userId":"17774416216702601338"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"rzRFMdfRsLAN","executionInfo":{"status":"ok","timestamp":1659228665697,"user_tz":-540,"elapsed":6,"user":{"displayName":"bong bong","userId":"17774416216702601338"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["mode = 'pool'\n","if mode == 'cola_':\n","        \n","    with open (mode +'.dill', 'wb') as f:\n","        model = {\n","            'TEXT' : TEXT,\n","            \"LABEL\" : LABEL,\n","            'classifier' : lstm_classifier \n","        }\n","        dill.dump(model, f)\n","\n","elif mode =='pool':\n","        \n","    with open ('pool_model.dill', 'wb') as f:\n","        model = {\n","            'TEXT' : TEXT,\n","            \"LABEL\" : LABEL,\n","            'classifier' : lstm_pool_classifier \n","        }\n","        dill.dump(model, f)"],"metadata":{"id":"qqoCfgXQn_9r","executionInfo":{"status":"ok","timestamp":1659228850125,"user_tz":-540,"elapsed":803,"user":{"displayName":"bong bong","userId":"17774416216702601338"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["%cd /content/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cWqwoQeBvN6v","executionInfo":{"status":"ok","timestamp":1659228809195,"user_tz":-540,"elapsed":314,"user":{"displayName":"bong bong","userId":"17774416216702601338"}},"outputId":"3c7cdc5a-f980-4a56-a8ff-e9974a8e029e"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}]},{"cell_type":"code","source":["def test(model, test_loader, device):\n","    model.eval()\n","    with torch.no_grad():\n","        y_real = []\n","        y_pred = []\n","\n","        for batch in test_loader :\n","            text = batch.text\n","            label = batch.label.type(torch.FloatTensor)\n","            text = text.to(device)\n","\n","            output = model(text).flatten().cpu()\n","\n","            y_real += [label]\n","            y_pred += [output]\n","\n","        y_real = torch.cat(y_real)\n","        y_pred = torch.cat(y_pred)\n","    \n","    fpr , tpr , _ = roc_curve(y_real, y_pred)\n","    auroc = auc(fpr, tpr)\n","    return auroc"],"metadata":{"id":"bB0TMBRWq_Mb","executionInfo":{"status":"ok","timestamp":1659228665697,"user_tz":-540,"elapsed":5,"user":{"displayName":"bong bong","userId":"17774416216702601338"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["_ = lstm_pool_classifier.cpu()\n","test_auroc = test(lstm_pool_classifier, cola_test_iterator, \"cpu\")\n","\n","print(f'test AUROC : {test_auroc:.5f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x3yNsbaZrzTG","executionInfo":{"status":"ok","timestamp":1659228881579,"user_tz":-540,"elapsed":2138,"user":{"displayName":"bong bong","userId":"17774416216702601338"}},"outputId":"6d614884-6f1c-459a-f8c4-1bbdfb18def8"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["test AUROC : 0.54942\n"]}]},{"cell_type":"code","source":["def predict_problem(model_path, problem):\n","    with open(model_path, 'rb') as f:\n","        model = dill.load(f)\n","    TEXT = model[\"TEXT\"]\n","    classifier = model[\"classifier\"]\n","\n","    problem = list(map(lambda x : x.replace(\"[\",\"\").replace(\"]\",\"\"), problem))\n","    tokenized_sentances = [word_tokenize(sentence) for sentence in problem]\n","    sentences = []\n","    for tokenized_sentence in tokenized_sentances:\n","        sentences.append([TEXT.vocab.stoi[word] for word in tokenized_sentence])\n","\n","    with torch.no_grad():\n","        classifier.eval()\n","        predict = []\n","        for sentance in sentences:\n","            sentance = torch.LongTensor([sentance])\n","            predict += [classifier(sentance).item()]\n","    \n","    score_df = pd.DataFrame(predict).T\n","    score_df.column = [f'answer_{i}thscore' for i in range(1,10)] \n","\n","    return score_df"],"metadata":{"id":"oTN8mS6A-pAm","executionInfo":{"status":"ok","timestamp":1659229009408,"user_tz":-540,"elapsed":328,"user":{"displayName":"bong bong","userId":"17774416216702601338"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["problem = [ \n","    \"Competitive activities can be more than just performance showcases which the best is recognized and the rest are overlooked.\",\n","    \"The provision of timely, constructive feedback to participants on performance is an asset that some competitions and contests offer.\",\n","    \"The provision of that type of feedback can be interpreted as shifting the emphasis to demonstrating superior performance but not necessarily excellence.\",\n","    \"The emphasis on superiority is what we typically see as fostering a detrimental effect of competition.\",\n","    \"Information about performance can be very helpful, not only to the participant who does not win or place but also to those who do.\",\n","    \"People from more individualistic cultural contexts tend to be motivated to maintain self-focused agency or control 1 as these serve as the basis of one’s self-worth.\",\n","    \"With this form of agency comes the belief that individual successes 2 depending primarily on one’s own abilities and actions, and thus, whether by influencing the environment or trying to accept one’s circumstances, the use of control ultimately centers on the individual.\",\n","    \"The independent self may be more 3 driven to cope by appealing to a sense of agency or control.\",\n","    \"Research has shown 4 that East Asians prefer to receive, but not seek, more social support rather than seek personal control in certain cases.\",\n","    \"Therefore, people 5 who hold a more interdependent self-construal may prefer to cope in a way that promotes harmony in relationships.\",\n","]\n","problem_label = [0, 1, 1, 1, 1, 1, 0, 1, 1, 1]\n","\n","answer = predict_problem('/content/pool_model.dill', problem)\n","display(answer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":119},"id":"Qxe3_dZQ76W_","executionInfo":{"status":"ok","timestamp":1659229078953,"user_tz":-540,"elapsed":788,"user":{"displayName":"bong bong","userId":"17774416216702601338"}},"outputId":"d2939211-6623-4170-a135-ba63aecbf230"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n"]},{"output_type":"display_data","data":{"text/plain":["          0        1         2         3         4         5         6  \\\n","0  0.918525  0.92542  0.919904  0.928468  0.922836  0.921689  0.921076   \n","\n","          7         8         9  \n","0  0.943399  0.923975  0.922705  "],"text/html":["\n","  <div id=\"df-fcedf6f7-6fa6-4022-a48e-59efe9ac3dd1\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.918525</td>\n","      <td>0.92542</td>\n","      <td>0.919904</td>\n","      <td>0.928468</td>\n","      <td>0.922836</td>\n","      <td>0.921689</td>\n","      <td>0.921076</td>\n","      <td>0.943399</td>\n","      <td>0.923975</td>\n","      <td>0.922705</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fcedf6f7-6fa6-4022-a48e-59efe9ac3dd1')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-fcedf6f7-6fa6-4022-a48e-59efe9ac3dd1 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-fcedf6f7-6fa6-4022-a48e-59efe9ac3dd1');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}]}]}